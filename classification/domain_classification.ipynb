{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scanned_doc_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtlfx9VhAzI/QV4D5+ZmPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristineLong/document/blob/main/scanned_doc_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doUv4WUTe8mh"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdDlwz8pamuO"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from keras import backend as k\r\n",
        "import shutil\r\n",
        "import os\r\n",
        "import tarfile\r\n",
        "import pandas as pd\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "from sklearn.manifold import TSNE\r\n",
        "from sklearn import preprocessing\r\n",
        "import pandas as pd\r\n",
        "from multiprocessing import Process# this is used for multithreading\r\n",
        "import multiprocessing\r\n",
        "import codecs# this is used for file operations \r\n",
        "import random as r\r\n",
        "import time\r\n",
        "import math\r\n",
        "import cv2\r\n",
        "from tqdm import tqdm_notebook as tqdm\r\n",
        "from sklearn.metrics import log_loss,confusion_matrix\r\n",
        "from keras import applications\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras import optimizers\r\n",
        "from keras.models import Sequential, Model \r\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,MaxPooling2D,Conv2D,Dropout,BatchNormalization\r\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.preprocessing import image\r\n",
        "from sklearn.datasets import load_files\r\n",
        "import cv2\r\n",
        "import pickle\r\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,precision_score,recall_score\r\n",
        "from statistics import mode\r\n",
        "from sklearn.utils.multiclass import unique_labels\r\n",
        "# Don't pre-allocate memory; allocate as-needed\r\n",
        "#config = tf.ConfigProto()\r\n",
        "#config.gpu_options.allow_growth = True\r\n",
        "\r\n",
        "# Create a session with the above options specified.\r\n",
        "#k.tensorflow_backend.set_session(tf.Session(config=config))\r\n",
        "\r\n",
        "from keras.callbacks import ReduceLROnPlateau\r\n",
        "from keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgkRnIXEfMAD"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdXAzLXafO3l"
      },
      "source": [
        "# Code to unzip the raw data\r\n",
        "file_path=\"rvl-cdip.tar.gz\"\r\n",
        "\r\n",
        "\r\n",
        "import tarfile\r\n",
        "tar = tarfile.open(file_path)\r\n",
        "tar.extractall()\r\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syqQ0hwxfQif"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sD03j1bfXsH"
      },
      "source": [
        "classes = {'0': 'letter',\r\n",
        " '1': 'form',\r\n",
        " '10': 'budget',\r\n",
        " '11': 'invoice',\r\n",
        " '12': 'presentation',\r\n",
        " '13': 'questionnaire',\r\n",
        " '14': 'resume',\r\n",
        " '15': 'memo',\r\n",
        " '2': 'email',\r\n",
        " '3': 'handwritten',\r\n",
        " '4': 'advertisement',\r\n",
        " '5': 'scientific report',\r\n",
        " '6': 'scientific publication',\r\n",
        " '7': 'specification',\r\n",
        " '8': 'file folder',\r\n",
        " '9': 'news article'}\r\n",
        "\r\n",
        "label_path='labels/'\r\n",
        "\r\n",
        "# This function will create an index file with image paths and labels in csv format\r\n",
        "# obtained csv will have two columns path(path to acess the image),label(class of the image)\r\n",
        "def create_csv(file_path):\r\n",
        "    images=[]\r\n",
        "    labels=[]\r\n",
        "    label_file=pd.DataFrame(columns=['path','label'],index=None)\r\n",
        "    file=open(file_path)\r\n",
        "    for ele in file:\r\n",
        "        images.append(ele.split(' ')[0])\r\n",
        "        labels.append(ele.split(' ')[1].rstrip())\r\n",
        "    label_file.path=images\r\n",
        "    label_file.label=labels\r\n",
        "    return label_file\r\n",
        "\r\n",
        "train_label_path=label_path+'train.txt' \r\n",
        "test_label_path=label_path+'test.txt' \r\n",
        "val_label_path=label_path+'val.txt'\r\n",
        "# creating index file for train,test and val dataset\r\n",
        "train_label=create_csv(train_label_path)\r\n",
        "test_label=create_csv(test_label_path)\r\n",
        "val_label=create_csv(val_label_path)\r\n",
        "    \r\n",
        "# Creating train,validation and Test directories\r\n",
        "os.mkdir('train')\r\n",
        "os.mkdir('test')\r\n",
        "os.mkdir('val')\r\n",
        "# run this cell to enable intra domain transfer learning\r\n",
        "regions = ['Whole','header', 'footer', 'left_body', 'right_body']\r\n",
        "for region in regions:\r\n",
        "    os.mkdir('train/'+region)\r\n",
        "    os.mkdir('val/'+region)\r\n",
        "classes_name=[v for (k,v) in classes.items()]\r\n",
        "for region in regions:\r\n",
        "    for label in classes_name:\r\n",
        "        os.mkdir('train/'+region+'/'+label)\r\n",
        "        os.mkdir('val/'+region+'/'+label)\r\n",
        "# Moving files for test directory from common directory\r\n",
        "folders=[classes[str(i)] for i in range(16)]\r\n",
        "for folder in folders:\r\n",
        "    if(os.path.exists('test/'+folder)== False):\r\n",
        "        os.mkdir('test/'+folder)\r\n",
        "for i in tqdm(range(len(test_label))):\r\n",
        "    if(os.path.exists('images/'+test_label.iloc[i].path)):\r\n",
        "        source='images/'+test_label.iloc[i].path\r\n",
        "        dest='test/'+classes[str(test_label.iloc[i].label)]\r\n",
        "        if(os.path.exists(dest+'/'+source.split('/')[-1])==False):\r\n",
        "            shutil.move(source,dest)\r\n",
        " \r\n",
        "# # Moving files for train directory from common directory\r\n",
        "for i in tqdm(range(len(train_label))):\r\n",
        "    if(os.path.exists('images/'+train_label.iloc[i].path)):\r\n",
        "        source='images/'+train_label.iloc[i].path\r\n",
        "        dest='train/Whole/'+classes[str(train_label.iloc[i].label)]\r\n",
        "        if(os.path.exists(dest+'/'+source.split('/')[-1])==False):\r\n",
        "            shutil.move(source,dest)\r\n",
        "\r\n",
        "#  Moving files for validation directory from common directory\r\n",
        "for i in tqdm(range(len(val_label))):\r\n",
        "    if(os.path.exists('images/'+val_label.iloc[i].path)):\r\n",
        "        source='images/'+val_label.iloc[i].path\r\n",
        "        dest='val/Whole/'+classes[str(val_label.iloc[i].label)]\r\n",
        "        if(os.path.exists(dest+'/'+source.split('/')[-1])==False):\r\n",
        "            shutil.move(source,dest)\r\n",
        "\r\n",
        "val_dir='val/Whole'\r\n",
        "count,limit=0,2000\r\n",
        "for folder in tqdm(os.listdir(val_dir)):\r\n",
        "  #os.shuffle(val_dir+'/'+folder)\r\n",
        "  for image in os.listdir(val_dir+'/'+folder):\r\n",
        "        img = cv2.imread(val_dir+'/'+folder+'/'+image,0)\r\n",
        "        height = img.shape[0]\r\n",
        "        width = img.shape[1]\r\n",
        "        header = img[0:(int(height*0.33)), 0:width]\r\n",
        "        footer = img[int(height*0.67):height, 0:width]\r\n",
        "        left_body = img[int(height*0.33):int(height*0.67), 0:int(width*0.5)]\r\n",
        "        right_body = img[int(height*0.33):int(height*0.67), int(width*0.5):width]\r\n",
        "        header_path='val/header/'+folder+'/'+image.split('/')[-1]\r\n",
        "        footer_path='val/footer/'+folder+'/'+image.split('/')[-1]\r\n",
        "        left_path='val/left_body/'+folder+'/'+image.split('/')[-1]\r\n",
        "        right_path='val/right_body/'+folder+'/'+image.split('/')[-1]\r\n",
        "        if(os.path.exists(header_path)==False):\r\n",
        "            cv2.imwrite(header_path, header)\r\n",
        "        if(os.path.exists(footer_path)==False):\r\n",
        "            cv2.imwrite(footer_path, footer)\r\n",
        "        if(os.path.exists(left_path)==False):\r\n",
        "            cv2.imwrite(left_path, left_body)\r\n",
        "        if(os.path.exists(right_path)==False):\r\n",
        "            cv2.imwrite(right_path, right_body)\r\n",
        "        count+=1\r\n",
        "        if(count==limit):\r\n",
        "            break\r\n",
        "\r\n",
        "train_dir='train/Whole'\r\n",
        "count,limit=0,2000\r\n",
        "for folder in tqdm(os.listdir(train_dir)):\r\n",
        "  #os.shuffle(train_dir+'/'+folder)\r\n",
        "  count=0\r\n",
        "    for image in os.listdir(train_dir+'/'+folder):\r\n",
        "        img = cv2.imread(train_dir+'/'+folder+'/'+image,0)\r\n",
        "        height = img.shape[0]\r\n",
        "        width = img.shape[1]\r\n",
        "        header = img[0:(int(height*0.33)), 0:width]\r\n",
        "        footer = img[int(height*0.67):height, 0:width]\r\n",
        "        left_body = img[int(height*0.33):int(height*0.67), 0:int(width*0.5)]\r\n",
        "        right_body = img[int(height*0.33):int(height*0.67), int(width*0.5):width]\r\n",
        "        header_path='train/header/'+folder+'/'+image.split('/')[-1]\r\n",
        "        footer_path='train/footer/'+folder+'/'+image.split('/')[-1]\r\n",
        "        left_path='train/left_body/'+folder+'/'+image.split('/')[-1]\r\n",
        "        right_path='train/right_body/'+folder+'/'+image.split('/')[-1]\r\n",
        "        if(os.path.exists(header_path)==False):\r\n",
        "            cv2.imwrite(header_path, header)\r\n",
        "        if(os.path.exists(footer_path)==False):\r\n",
        "            cv2.imwrite(footer_path, footer)\r\n",
        "        if(os.path.exists(left_path)==False):\r\n",
        "            cv2.imwrite(left_path, left_body)\r\n",
        "        if(os.path.exists(right_path)==False):\r\n",
        "            cv2.imwrite(right_path, right_body)\r\n",
        "        count+=1\r\n",
        "        if(count==limit):\r\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAAR_tTTfYmZ"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4Hvgt3KbEbG"
      },
      "source": [
        "# Training configuaration for CNN- to be trained on whole images\r\n",
        "img_width, img_height = 224,224\r\n",
        "train_dir = \"train/Whole\"\r\n",
        "val_dir = \"val/Whole\"\r\n",
        "test_dir=\"test\"\r\n",
        "nb_train_samples = 320000\r\n",
        "nb_validation_samples = 40000 \r\n",
        "batch_size = 50\r\n",
        "epochs = 20\r\n",
        "num_classes=16\r\n",
        "log=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYm4vtwua8e3"
      },
      "source": [
        "# preparing Training and Validation data using ImageDataGenerator\r\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, featurewise_std_normalization=True)\r\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255, featurewise_std_normalization=True)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\r\n",
        "                                                    target_size = (img_height, img_width),\r\n",
        "                                                    batch_size = batch_size, \r\n",
        "                                                    class_mode = \"categorical\")\r\n",
        "\r\n",
        "val_generator = val_datagen.flow_from_directory(val_dir,\r\n",
        "                                                target_size = (img_height, img_width),\r\n",
        "                                                batch_size = batch_size, \r\n",
        "                                                class_mode = \"categorical\")\r\n",
        "\r\n",
        "# Importing keras InceptionRsnetv2 pretrained model (on ImageNet)\r\n",
        "# We will use the ImageNet weight to initialize the model and fine tune using backpropagation(Transfer Learning) \r\n",
        "\r\n",
        "model=applications.InceptionResNetV2(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\r\n",
        "#for layer in model.layers[:15]:\r\n",
        "#    layer.trainable = False\r\n",
        "#Adding custom Layers \r\n",
        "x = model.output\r\n",
        "x = Dropout(0.5)(x)\r\n",
        "x = Flatten()(x)\r\n",
        "output = Dense(num_classes, activation=\"softmax\")(x)\r\n",
        "model = Model(input = model.input, output = output)\r\n",
        "\r\n",
        "#model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=[\"accuracy\"])\r\n",
        "checkpoint = ModelCheckpoint(\"inceptionresnet.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\r\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, min_lr=0.0001,mode='auto')\r\n",
        "callbacks=[checkpoint,reduce_lr]\r\n",
        "history=model.fit_generator(train_generator,\r\n",
        "                            samples_per_epoch =nb_train_samples//batch_size,\r\n",
        "                            epochs = epochs,\r\n",
        "                            validation_data = val_generator,\r\n",
        "                            validation_steps =math.ceil(nb_validation_samples//(batch_size)),\r\n",
        "                            callbacks = callbacks,verbose=1)\r\n",
        "log.append(history)\r\n",
        "model.save('Inceptionresnet_final.h5')\r\n",
        "\r\n",
        "model=applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\r\n",
        "#for layer in model.layers[:15]:\r\n",
        "#    layer.trainable = False\r\n",
        "#Adding custom Layers \r\n",
        "x = model.output\r\n",
        "x = Flatten()(x)\r\n",
        "output = Dense(num_classes, activation=\"softmax\")(x)\r\n",
        "model = Model(input = model.input, output = output)\r\n",
        "checkpoint = ModelCheckpoint(\"vgg16.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\r\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, min_lr=0.0001,mode='auto')\r\n",
        "callbacks=[checkpoint,reduce_lr]\r\n",
        "history=model.fit_generator(train_generator,\r\n",
        "                            samples_per_epoch =nb_train_samples//batch_size,\r\n",
        "                            epochs = epochs,\r\n",
        "                            validation_data = val_generator,\r\n",
        "                            validation_steps = math.ceil(nb_validation_samples//(batch_size)),\r\n",
        "                            callbacks = callbacks,verbose=1)\r\n",
        "model.save('vgg16_final.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmafZNSt31Cg"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avMboBnA07pf"
      },
      "source": [
        "model1=load_model('vgg16.h5')\r\n",
        "model2=load_model('resinception.h5')\r\n",
        "img_width, img_height = 224,224\r\n",
        "train_dir = \"train\"\r\n",
        "val_dir = \"val\"\r\n",
        "test_dir=\"test\"\r\n",
        "nb_train_samples = 300000\r\n",
        "nb_validation_samples = 32000\r\n",
        "batch_size = 1280\r\n",
        "epochs = 20\r\n",
        "num_classes=16\r\n",
        "log=[]\r\n",
        "# Test Data generator to generate test data in same format of training data\r\n",
        "test_datagen = ImageDataGenerator(\r\n",
        "rescale = 1./255,\r\n",
        "featurewise_std_normalization=True)\r\n",
        "test_generator = test_datagen.flow_from_directory(\r\n",
        "test_dir,\r\n",
        "target_size = (img_height, img_width),\r\n",
        "batch_size = batch_size,shuffle='True',\r\n",
        "class_mode = \"categorical\")\r\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,precision_score,recall_score\r\n",
        "from statistics import mode\r\n",
        "from sklearn.utils.multiclass import unique_labels\r\n",
        "def eval_model(model1,model2,test_generator,limit):\r\n",
        "    \"\"\"\r\n",
        "    This function creates an ensamble of candidate CNN models and predict the result\r\n",
        "    model1,model2,model3 -- candidate models\r\n",
        "    test_generator -- Instance of ItemDataGenerator to randomly generate test data\r\n",
        "    limit -- limits the number of test samples\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    try:\r\n",
        "         x,y=test_generator.next()\r\n",
        "    except:\r\n",
        "        print('')\r\n",
        "    y_pred=[]\r\n",
        "    y_true=[]\r\n",
        "    count=0\r\n",
        "    #print(len(x))\r\n",
        "    for i in range(len(x)):\r\n",
        "        #pred1=np.argmax(model1.predict(np.expand_dims(x[i], axis=0)))\r\n",
        "        #pred2=np.argmax(model2.predict(np.expand_dims(x[i], axis=0)))\r\n",
        "        #pred3=np.argmax(model3.predict(np.expand_dims(x[i], axis=0)))\r\n",
        "        try:\r\n",
        "            # If there are clear majority in prediction add the majority voted class\r\n",
        "            y_pred.append(np.argmax(model1.predict(np.expand_dims(x[i], axis=0))+model2.predict(np.expand_dims(x[i], axis=0))))\r\n",
        "        except:\r\n",
        "            # else select prediction of second model \r\n",
        "            y_pred.append(pred2)\r\n",
        "        y_true.append(np.argmax(y[i]))\r\n",
        "        count+=1\r\n",
        "        # limit the number of samples to be considered\r\n",
        "        if(count==limit):\r\n",
        "            break\r\n",
        "    return y_pred,y_true\r\n",
        "\r\n",
        "def get_result(y_pred,y_true):\r\n",
        "    \"\"\"\r\n",
        "    This function evaluate the performance(accuracy,f1-score,precision,recall,confusion matrix of the network).\r\n",
        "    \"\"\"\r\n",
        "    print('-----Model Evaluation------')\r\n",
        "    accuracy=np.round(accuracy_score(y_pred,y_true),3)\r\n",
        "    f1=np.round(f1_score(y_pred,y_true,average='macro'),3)\r\n",
        "    precision=np.round(precision_score(y_pred,y_true,average='macro'),3)\r\n",
        "    recall=np.round(recall_score(y_pred,y_true,average='macro'),3)\r\n",
        "    print('Accuracy:',accuracy*100,'%')\r\n",
        "    print('Macro F1 Score:',f1)\r\n",
        "    print('Precision Score:',precision)\r\n",
        "    print('Recall Score:',recall)\r\n",
        "    #plot_confusion_matrix(y_true,y_pred)\r\n",
        "    return accuracy,f1,precision,recall\r\n",
        "    \r\n",
        "y_pred,y_true=eval_model(model1,model1,test_generator,30000)\r\n",
        "accuracy,f1,precision,recall=get_result(y_pred,y_true)\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5QRekroAM9p"
      },
      "source": [
        "Full repo: https://github.com/arpan65/Scanned-document-classification-using-deep-learning/tree/master/scripts"
      ]
    }
  ]
}
